{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Smoulvad01/AI-C1-image-/blob/main/Inspecting_image_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78641402",
      "metadata": {
        "id": "78641402"
      },
      "source": [
        "# <font color='green'>Import and Path</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a17a795f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a17a795f",
        "outputId": "13a3dbf3-3ce2-4551-8906-13bc5698053e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "from PIL import Image # To display images\n",
        "from sklearn.decomposition import NMF, PCA\n",
        "from collections import Counter\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "# Helper libraries\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from importlib import reload\n",
        "from collections import Counter\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "reload(plt)\n",
        "np.set_printoptions(suppress=True)\n",
        "print(tf.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNuKRhQFiK3l",
        "outputId": "62eb0fb0-1ca1-4272-dd84-f02770fa212f"
      },
      "id": "VNuKRhQFiK3l",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "directory_train = \"/content/drive/MyDrive/AI and ML /dataset_new-2/train\"\n",
        "directory_test = \"/content/drive/MyDrive/AI and ML /dataset_new-2/test\""
      ],
      "metadata": {
        "id": "Ac3NOuIz41Wy"
      },
      "id": "Ac3NOuIz41Wy",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='green'>Inspect Data Before Processing </font>"
      ],
      "metadata": {
        "id": "tfqsPWH_3dZf"
      },
      "id": "tfqsPWH_3dZf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Image Sizes"
      ],
      "metadata": {
        "id": "q9HV0m8hNdOg"
      },
      "id": "q9HV0m8hNdOg"
    },
    {
      "cell_type": "code",
      "source": [
        "# check for smallest and largest image \n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Initialize variables to hold the smallest and largest images\n",
        "smallest_image = None\n",
        "largest_image = None\n",
        "\n",
        "smallest_image_size = float('inf')  # set initial smallest size to infinity\n",
        "largest_image_size = float('-inf')  # set initial largest size to negative infinity\n",
        "\n",
        "# Iterate over all images in the specified directory\n",
        "for filename in os.listdir(directory_train+\"/Open/\"):\n",
        "    #if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  # add more file types if needed\n",
        "    img = Image.open(os.path.join(directory_train+\"/Open/\", filename))\n",
        "    width, height = img.size\n",
        "    image_size = width * height  # total pixel count\n",
        "    #print(\"Debug: Image size: \" + str(image_size))\n",
        "    # Check if current image is the smallest one\n",
        "    if image_size < smallest_image_size:\n",
        "        smallest_image_size = image_size\n",
        "        smallest_image = img\n",
        "\n",
        "    # Check if current image is the largest one\n",
        "    if image_size > largest_image_size:\n",
        "        largest_image_size = image_size\n",
        "        largest_image = img\n",
        "\n",
        "print(\"Largest image size: \" + str(largest_image_size))\n",
        "print(\"Smallest image size: \" + str(smallest_image_size))\n",
        "# Now smallest_image and largest_image hold the smallest and largest images respectively."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bwd8UdyytaNv",
        "outputId": "b93e1963-3afd-4bab-b0ea-e812950f5782"
      },
      "id": "Bwd8UdyytaNv",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Largest image size: 2293710\n",
            "Smallest image size: 2250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Statistics on Dataset Images "
      ],
      "metadata": {
        "id": "7xmh6wFH3yzn"
      },
      "id": "7xmh6wFH3yzn"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def image_sizes(directory):\n",
        "    sizes = []\n",
        "    for filename in os.listdir(directory):\n",
        "        img = Image.open(os.path.join(directory, filename))\n",
        "        width, height = img.size\n",
        "        sizes.append(width * height)\n",
        "    return sizes\n",
        "\n",
        "# Calculate sizes\n",
        "sizes_train_open = image_sizes(directory_train+\"/Open/\")\n",
        "sizes_train_closed = image_sizes(directory_train+\"/Closed/\")\n",
        "sizes_test_open = image_sizes(directory_test+\"/Open/\")\n",
        "sizes_test_closed = image_sizes(directory_test+\"/Closed/\")\n",
        "\n",
        "# Calculate statistics\n",
        "def calculate_statistics(sizes):\n",
        "    return {\n",
        "        'mean': np.mean(sizes),\n",
        "        'median': np.median(sizes),\n",
        "        'min': np.min(sizes),\n",
        "        'max': np.max(sizes),\n",
        "        'std': np.std(sizes),\n",
        "    }\n",
        "\n",
        "# Print statistics\n",
        "for name, sizes in [('Train/Open', sizes_train_open), \n",
        "                    ('Train/Closed', sizes_train_closed), \n",
        "                    ('Test/Open', sizes_test_open), \n",
        "                    ('Test/Closed', sizes_test_closed)]:\n",
        "    stats = calculate_statistics(sizes)\n",
        "    print(f\"Image size statistics in {name}: \")\n",
        "    for stat, value in stats.items():\n",
        "        print(f\"  {stat}: {value}\")\n",
        "\n",
        "\n",
        "def image_sizes(directory):\n",
        "    sizes = []\n",
        "    for filename in os.listdir(directory):\n",
        "        img = Image.open(os.path.join(directory, filename))\n",
        "        width, height = img.size\n",
        "        sizes.append(width * height)\n",
        "    return sizes\n",
        "\n",
        "# Get directories\n",
        "directories = [directory_train+\"/Open/\", directory_train+\"/Closed/\",\n",
        "               directory_test+\"/Open/\", directory_test+\"/Closed/\"]\n",
        "\n",
        "# Calculate sizes for all directories\n",
        "sizes_all = []\n",
        "for directory in directories:\n",
        "    sizes_all.extend(image_sizes(directory))\n",
        "\n",
        "# Calculate statistics\n",
        "def calculate_statistics(sizes):\n",
        "    return {\n",
        "        'mean': np.mean(sizes),\n",
        "        'median': np.median(sizes),\n",
        "        'min': np.min(sizes),\n",
        "        'max': np.max(sizes),\n",
        "        'std': np.std(sizes),\n",
        "    }\n",
        "\n",
        "# Print statistics\n",
        "stats = calculate_statistics(sizes_all)\n",
        "print(f\"Image size statistics for the aggregate dataset: \")\n",
        "for stat, value in stats.items():\n",
        "    print(f\"  {stat}: {value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPpcUkyO3vrD",
        "outputId": "e13b93e3-a9b7-4310-b652-219ffadb9e13"
      },
      "id": "ZPpcUkyO3vrD",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image size statistics in Train/Open: \n",
            "  mean: 142565.2414910859\n",
            "  median: 96900.0\n",
            "  min: 2250\n",
            "  max: 2293710\n",
            "  std: 206027.72118035448\n",
            "Image size statistics in Train/Closed: \n",
            "  mean: 169454.55591572123\n",
            "  median: 92700.0\n",
            "  min: 4158\n",
            "  max: 2640625\n",
            "  std: 305579.49696381553\n",
            "Image size statistics in Test/Open: \n",
            "  mean: 146018.79816513762\n",
            "  median: 95100.0\n",
            "  min: 3960\n",
            "  max: 1638400\n",
            "  std: 215512.52309630506\n",
            "Image size statistics in Test/Closed: \n",
            "  mean: 163292.22018348624\n",
            "  median: 91800.0\n",
            "  min: 4928\n",
            "  max: 1638400\n",
            "  std: 273434.65731457766\n",
            "Image size statistics for the aggregate dataset: \n",
            "  mean: 155806.55371900825\n",
            "  median: 94200.0\n",
            "  min: 2250\n",
            "  max: 2640625\n",
            "  std: 258807.10081300576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visually Inspect Images "
      ],
      "metadata": {
        "id": "HYwnzQiP6pe7"
      },
      "id": "HYwnzQiP6pe7"
    },
    {
      "cell_type": "code",
      "source": [
        "# Visually inspect random images to get to know dataset and compare to processed data later\n",
        "folder_path = \"/content/drive/MyDrive/dataset_new/test/Open/\"\n",
        "\n",
        "image_list = os.listdir(folder_path)\n",
        "random.shuffle(image_list)\n",
        "\n",
        "\n",
        "for i in range(3):\n",
        "    if i < len(image_list):\n",
        "        image_path = os.path.join(folder_path, image_list[i])\n",
        "        test_img = cv2.imread(image_path)\n",
        "        print(\"Original Image:\", image_list[i])\n",
        "        imageRGB = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
        "        print_original_image = Image.fromarray(imageRGB)\n",
        "        print_original_image.show()\n",
        "    else:\n",
        "        break"
      ],
      "metadata": {
        "id": "o2jqq91yBouy"
      },
      "id": "o2jqq91yBouy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "0d38d346",
      "metadata": {
        "id": "0d38d346"
      },
      "source": [
        "# <font color='green'>Inspect Data After Processing</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and Process Data using Keras"
      ],
      "metadata": {
        "id": "9WcgsM1Z4GkZ"
      },
      "id": "9WcgsM1Z4GkZ"
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image_dataset(directory):\n",
        "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "        directory,\n",
        "        labels='inferred',\n",
        "        label_mode='int',\n",
        "        class_names=None,\n",
        "        color_mode='grayscale',\n",
        "        batch_size=32,\n",
        "        image_size=(256, 256),\n",
        "        shuffle=True,\n",
        "        seed=42,\n",
        "        validation_split=False,\n",
        "        interpolation='mitchellcubic',\n",
        "        follow_links=False,\n",
        "        crop_to_aspect_ratio=False,\n",
        "    )\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "QoxgKvC_0h_6"
      },
      "id": "QoxgKvC_0h_6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define train_images and test_images\n",
        "train_images = load_image_dataset(directory_train)\n",
        "test_images = load_image_dataset(directory_test)"
      ],
      "metadata": {
        "id": "pAUDykpl0lB-"
      },
      "id": "pAUDykpl0lB-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a987d5d6",
      "metadata": {
        "id": "a987d5d6"
      },
      "outputs": [],
      "source": [
        "#Labeling to give classnames \n",
        "class_names = train_images.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the train test split ratio \n",
        "train_size = 1234\n",
        "test_size = 218\n",
        "\n",
        "print(test_size/(train_size+test_size))"
      ],
      "metadata": {
        "id": "t2FhvL_X0r27"
      },
      "id": "t2FhvL_X0r27",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inspect Image Labels"
      ],
      "metadata": {
        "id": "e6dOEASvNvU0"
      },
      "id": "e6dOEASvNvU0"
    },
    {
      "cell_type": "code",
      "source": [
        "# get the count of elements in the batched datasets\n",
        "# For training data\n",
        "train_class_counts = Counter()\n",
        "\n",
        "for images, labels in train_images:\n",
        "    train_class_counts.update(labels.numpy())\n",
        "\n",
        "print(\"Training data class counts:\", train_class_counts)\n",
        "\n",
        "# For testing data\n",
        "test_class_counts = Counter()\n",
        "\n",
        "for images, labels in test_images:\n",
        "    test_class_counts.update(labels.numpy())\n",
        "\n",
        "print(\"Testing data class counts:\", test_class_counts)"
      ],
      "metadata": {
        "id": "_XsU--hDOqpd"
      },
      "id": "_XsU--hDOqpd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize the Images"
      ],
      "metadata": {
        "id": "8Qo0SZlIMBw_"
      },
      "id": "8Qo0SZlIMBw_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd2baf2e",
      "metadata": {
        "id": "cd2baf2e"
      },
      "outputs": [],
      "source": [
        "# plotting to inspect images visually and check correct labelling \n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_images.take(1):\n",
        "  for i in range(12):\n",
        "    ax = plt.subplot(3,4 , i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"), cmap='gray')\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.grid(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inspect Batches"
      ],
      "metadata": {
        "id": "b27GDR-vS3zg"
      },
      "id": "b27GDR-vS3zg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8857c0d6",
      "metadata": {
        "id": "8857c0d6"
      },
      "outputs": [],
      "source": [
        "# get the count of batches\n",
        "batch_count = tf.data.experimental.cardinality(train_images).numpy()\n",
        "print(\"Number of batches: \" + str(batch_count))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inspect the batches\n",
        "for images, labels in train_images.take(1):\n",
        "    print(images.shape) #(1) denotes the number of images in the batch. (2) denotes the height and width of each image in pixels.(4) denotes the number of color channels in each image, which is typically RGB (red, green, blue) or grayscale.\n",
        "    print(images.dtype)\n",
        "    print(labels.shape)\n",
        "    print(labels.dtype)"
      ],
      "metadata": {
        "id": "TRT1Dsc2rMEJ"
      },
      "id": "TRT1Dsc2rMEJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if all images are the same size in the batches\n",
        "def check_image_sizes(dataset):\n",
        "    for images, labels in dataset.take(1):\n",
        "        for i in range(len(images)):\n",
        "            print(f\"Image {i+1} size: {images[i].shape}\")\n",
        "\n",
        "# Check sizes of train images\n",
        "print(\"Train images sizes:\")\n",
        "check_image_sizes(train_images)\n",
        "\n",
        "# Check sizes of test images\n",
        "print(\"Test images sizes:\")\n",
        "check_image_sizes(test_images)"
      ],
      "metadata": {
        "id": "sCLTiWOIBL9c"
      },
      "id": "sCLTiWOIBL9c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check For Corrupted Images"
      ],
      "metadata": {
        "id": "kCPCTfuJVqX7"
      },
      "id": "kCPCTfuJVqX7"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_image_paths(directory):\n",
        "    image_paths = []\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.endswith(\".jpg\") or file.endswith(\".jpeg\") or file.endswith(\".png\"):  # Add/modify file extensions to suit your dataset\n",
        "                image_paths.append(os.path.join(root, file))\n",
        "    return image_paths\n",
        "\n",
        "corrupted_images = []\n",
        "\n",
        "# Obtain all image paths from training and testing directories\n",
        "all_image_paths = get_all_image_paths(file_path_folder_train) + get_all_image_paths(file_path_folder_test)\n",
        "\n",
        "for img_path in all_image_paths:\n",
        "    try:\n",
        "        img = Image.open(img_path)\n",
        "        img.verify()  # This will raise an exception if the image is not valid\n",
        "    except (IOError, SyntaxError) as e:\n",
        "        corrupted_images.append(img_path)\n",
        "\n",
        "print(f\"Number of corrupted images: {len(corrupted_images)}\")"
      ],
      "metadata": {
        "id": "qNMn2APIVq9l"
      },
      "id": "qNMn2APIVq9l",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}